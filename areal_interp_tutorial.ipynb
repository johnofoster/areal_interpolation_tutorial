{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e4e96b-6307-4a40-8172-8bd7605d4406",
   "metadata": {},
   "source": [
    "### Import Modules and Packages\n",
    "\n",
    "This tutorial requires the use of one built-in Python module and a number of 3rd party ones. I'll quickly run through why we need each:\n",
    "\n",
    "* `random`: Helps to generate random points in Part 2 of the tutorial. A Python built-in module.\n",
    "* `geopandas`: For operations on GeoDataFrames\n",
    "* `json`: For plotting maps with Plotly\n",
    "* `matplotlib.pyplot`: For plotting figures and maps\n",
    "* `numpy`: Contains a number of statistical functions\n",
    "* `plotly.express`: For interactive plotting\n",
    "* `pandas`: For operations on DataFrames\n",
    "* `tobler`: Contains the areal interpolation functions. Part of the PySal library.\n",
    "* `scipy`: Contains a number of statistical functions\n",
    "* `shapely.geometry`: For the `Point` class which is used when generating the random points\n",
    "\n",
    "If you need help on importing modules then this guide from Real Python should help: [Python Modules and Packages â€“ An Introduction](https://realpython.com/python-modules-packages/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540f184-d595-4ca9-81c6-22448e9eef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt # Do I need this if all the plots are with gpd.explore() or px?\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tobler\n",
    "from scipy import stats\n",
    "from shapely.geometry import Point # Maybe I should import the whole module?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b7e9c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 - Areal Interpolation of Census Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be76d83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be4b0cf4-4fab-4f65-aea4-dce41f1c435e",
   "metadata": {},
   "source": [
    "### Read The Data\n",
    "\n",
    "We first need read the data from our `data/` directory and assign them to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001fae5c-1316-4e0a-acc9-baf0ad5ff5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the City of Ottawa census tracts data\n",
    "ct_gdf = gpd.read_file('data/ottawa_ct_pop_2016.gpkg')\n",
    "\n",
    "# Read the City of Ottawa dissemination areas data\n",
    "da_gdf = gpd.read_file('data/ottawa_da_pop_2016.gpkg')\n",
    "\n",
    "# Read the City of Ottawa neighborhoods data\n",
    "nbhd_gdf = gpd.read_file('data/ottawa_neighborhoods.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a8f50",
   "metadata": {},
   "source": [
    "### Inspect The Data\n",
    "\n",
    "The following methods from Pandas and GeoPandas are great ways to inspect DataFrames and GeoDataFrames. Note: The DataFrame methods also work on GeoDataFrames but `explore()` only works with GeoDataFrames\n",
    "\n",
    "* [`df.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html): Information about the DataFrame/GeoDataFrame\n",
    "* [`df.head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html): First n rows of the DataFrame/GeoDataFrame (defaults to 10 rows)\n",
    "* [`df.tail()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html): Last n rows of the DataFrame/GeoDataFrame (defaults to 10 rows) \n",
    "* [`df.sample()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html): Random sample of n rows of the DataFrame/GeoDataFrame (defaults to 10 rows) \n",
    "* [`gdf.explore()`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html): Interactive map of a GeoDataFrame\n",
    "* [`gdf.crs`](https://geopandas.org/en/stable/docs/user_guide/projections.html): Coordinate reference system information of a GeoDataFrame\n",
    "\n",
    "Just replace `df` or `gdf` before the dot notation with your DataFrame or GeoDataFrame's name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f19108",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6243359",
   "metadata": {},
   "source": [
    "ct_gdf['ct_pop_2016'] = ct_synth_gdf['ct_synth_pop']\n",
    "nbhd_gdf['nbhd_pop_est'] = nbhd_synth_gdf['nbhd_synth_pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3db67",
   "metadata": {},
   "source": [
    "#### Area Weighted Interpolation\n",
    "\n",
    "- [tobler.area_weighted.area_interpolate](https://pysal.org/tobler/generated/tobler.area_weighted.area_interpolate.html#tobler.area_weighted.area_interpolate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bcd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area weighted interpolation: census tracts to neighborhoods\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "ct_area_interp_gdf = tobler.area_weighted.area_interpolate(source_df=ct_gdf, \n",
    "                                                        target_df=nbhd_gdf,\n",
    "                                                        extensive_variables=['ct_pop_2016'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "ct_area_interp_gdf['ct_pop_2016'] = ct_area_interp_gdf['ct_pop_2016'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "ct_area_interp_gdf = ct_area_interp_gdf.rename({'ct_pop_2016':'ct_area_interp_est'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area weighted interpolation: dissemination areas to neighborhoods\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "da_area_interp_gdf = tobler.area_weighted.area_interpolate(source_df=da_gdf, \n",
    "                                                        target_df=nbhd_gdf,\n",
    "                                                        extensive_variables=['da_pop_2016'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "da_area_interp_gdf['da_pop_2016'] = da_area_interp_gdf['da_pop_2016'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "da_area_interp_gdf = da_area_interp_gdf.rename({'da_pop_2016':'da_area_interp_est'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c5b76",
   "metadata": {},
   "source": [
    "### Dasymetric Interpolation\n",
    "\n",
    "- [tobler.dasymetric.masked_area_interpolate](https://pysal.org/tobler/generated/tobler.dasymetric.masked_area_interpolate.html#tobler.dasymetric.masked_area_interpolate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad844b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasymetric interpolation: census tracts + urban landover to neighborhoods\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "# Perform dasymetric interpolation\n",
    "ct_dasy_interp_gdf = tobler.dasymetric.masked_area_interpolate(source_df=ct_gdf, \n",
    "                                            target_df=nbhd_gdf,\n",
    "                                            raster='data/ottawa_landcover.tif',\n",
    "                                            codes=[17],\n",
    "                                            extensive_variables=['ct_pop_2016'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "ct_dasy_interp_gdf['ct_pop_2016'] = ct_dasy_interp_gdf['ct_pop_2016'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "ct_dasy_interp_gdf = ct_dasy_interp_gdf.rename({'ct_pop_2016':'ct_dasy_interp_est'}, axis=1)\n",
    "\n",
    "# ~30 s ; ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasymetric interpolation: dissemination areas + urban landover to neighborhoods\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "# Perform dasymetric interpolation\n",
    "da_dasy_interp_gdf = tobler.dasymetric.masked_area_interpolate(source_df=da_gdf, \n",
    "                                                            target_df=nbhd_gdf,\n",
    "                                                            raster='data/ottawa_landcover.tif',\n",
    "                                                            codes=[17],\n",
    "                                                            extensive_variables=['da_pop_2016'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "da_dasy_interp_gdf['da_pop_2016'] = da_dasy_interp_gdf['da_pop_2016'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "da_dasy_interp_gdf = da_dasy_interp_gdf.rename({'da_pop_2016':'da_dasy_interp_est'}, axis=1)\n",
    "\n",
    "# ~1.5 mins : ignore warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bff6b",
   "metadata": {},
   "source": [
    "### Assessing the Interpolation Results\n",
    "\n",
    "Because the neighborhoods data came with a population estimate for each neighborhood (`nbhd_pop_est`) we can use it to compare those values against the interpolated values. It is very important to note that these assessments are very limited in their accuracy for a number of reasons:\n",
    "\n",
    "1. Metadata associated with the Ottawa neighborhood survey data does not specify the year of the population estimate. This data was first published to the Open Ottawa data portal on November 25, 2019 and then updated on June 2, 2021. The census tract population data comes from the 2016 census.\n",
    "2. Metadata associated with the Ottawa neighborhood survey data does not specify the methodology they used for estimating the neighborhood populations. Perhaps it came from an areal interpolation method similar to what we are using or perhaps it came from a higher resolution data set that the City of Ottawa has but which they don't publish (e.g. size of each households).\n",
    "3. The Ottawa neighborhood survey data indicates that the 'Beechwood Cemetery' and 'Notre-Dame Cemetery' neighborhoods have populations of 139 and 17, respectively, despite no evidence of residences within them. \n",
    "4. The sum of all the neighborhood population estimates is 867146 while the census_tracts' sum is 934243.\n",
    "\n",
    "Despite this we will go ahead and use these estimates to assess the interpolation results. We will do the following:\n",
    "\n",
    "1. Visual assessment of the percent error of each neighborhood (interpolated population vs `nbhd_pop_est`)\n",
    "2. Checking the population sums\n",
    "3. Statistical assessment of the Root Mean Square Error (RMSE) and Mean Bias Error (MBE) of each neighborhood (interpolated population vs `nbhd_pop_est`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results for comparison\n",
    "#---------------------------------\n",
    "\n",
    "# Create a list of the GeoDataFrames (drop the redundant geometry)\n",
    "dfs = [nbhd_gdf,\n",
    "        ct_area_interp_gdf.drop(columns='geometry'),\n",
    "        ct_dasy_interp_gdf.drop(columns='geometry'),\n",
    "        da_area_interp_gdf.drop(columns='geometry'),\n",
    "        da_dasy_interp_gdf.drop(columns='geometry'),]\n",
    "\n",
    "# Concatenate the GeoDataFrames\n",
    "interp_results_gdf = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Get into on the new interpolation results GeoDataFrame\n",
    "interp_results_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to assess the results\n",
    "# --------------------------------------\n",
    "\n",
    "# PE\n",
    "def percent_error(estimated, expected):\n",
    "    ''' Return Percent Error where estimated and expected are numeric or array-like'''\n",
    "    return abs(((estimated - expected) / expected) * 100)\n",
    "\n",
    "# RMSE\n",
    "def rmse(estimated, expected):\n",
    "    ''' Return Root Mean Square Error where estimated and expected are array-like'''\n",
    "    return np.sqrt(np.mean((estimated - expected) ** 2))\n",
    "\n",
    "# NRMSE\n",
    "def nrmse(estimated, expected):\n",
    "    ''' Return Normalized Root Mean Square Error where estimated and expected are array-like'''\n",
    "    return np.sqrt(np.mean((estimated - expected) ** 2))/np.std(estimated)\n",
    "\n",
    "# MBE\n",
    "def mbe(estimated, expected):\n",
    "    ''' Return Mean Bias Error where estimated and expected are array-like'''\n",
    "    return np.mean(estimated - expected)\n",
    "\n",
    "# MAE\n",
    "def mae(estimated, expected):\n",
    "    ''' Return Mean Mean Absolute Error where estimated and expected are array-like'''\n",
    "    return np.mean(abs(estimated - expected))\n",
    "\n",
    "# r value\n",
    "def r_value(estimated, expected):\n",
    "    ''' Return r value where estimated and expected are array-like.'''\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(estimated, expected)\n",
    "    return r_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Results\n",
    "# ----------------\n",
    "\n",
    "ct_area_est = interp_results_gdf['ct_area_interp_est']\n",
    "ct_dasy_est = interp_results_gdf['ct_dasy_interp_est']\n",
    "da_area_est = interp_results_gdf['da_area_interp_est']\n",
    "da_dasy_est = interp_results_gdf['da_dasy_interp_est']\n",
    "expected = interp_results_gdf['nbhd_pop_est']\n",
    "\n",
    "# Percent Error - create new columns in interp_results_gdf\n",
    "interp_results_gdf['ct_area_%_error'] = round(percent_error(ct_area_est, expected), 1)\n",
    "interp_results_gdf['ct_dasy_%_error'] = round(percent_error(ct_dasy_est, expected), 1)\n",
    "interp_results_gdf['da_area_%_error'] = round(percent_error(da_area_est, expected), 1)\n",
    "interp_results_gdf['da_dasy_%_error'] = round(percent_error(da_dasy_est, expected), 1)\n",
    "\n",
    "# Other statistics - create DataFrame of statistics\n",
    "interp_stats_df = pd.DataFrame({'Interpolation Method': ['Area Weighted','Area Weighted',\n",
    "                                                        'Dasymetric', 'Dasymetric'],\n",
    "                                'Source Geographies': ['Census Tracts', 'Dissemination Areas',\n",
    "                                                       'Census Tracts', 'Dissemination Areas'],\n",
    "                                'RMSE': [round(rmse(ct_area_est, expected), 2),\n",
    "                                        round(rmse(da_area_est, expected), 2),\n",
    "                                        round(rmse(ct_dasy_est, expected), 2),\n",
    "                                        round(rmse(da_dasy_est, expected), 2)],\n",
    "                                'NRMSE': [round(nrmse(ct_area_est, expected), 2),\n",
    "                                        round(nrmse(da_area_est, expected), 2),\n",
    "                                        round(nrmse(ct_dasy_est, expected), 2),\n",
    "                                        round(nrmse(da_dasy_est, expected), 2)],            \n",
    "                                'MBE': [round(mbe(ct_area_est, expected), 2),\n",
    "                                        round(mbe(da_area_est, expected), 2),\n",
    "                                        round(mbe(ct_dasy_est, expected), 2),\n",
    "                                        round(mbe(da_dasy_est, expected), 2)],\n",
    "                                'MAE': [round(mae(ct_area_est, expected), 2),\n",
    "                                        round(mae(da_area_est, expected), 2),\n",
    "                                        round(mae(ct_dasy_est, expected), 2),\n",
    "                                        round(mae(da_dasy_est, expected), 2)],\n",
    "                                'r': [round(r_value(ct_area_est, expected),2 ),\n",
    "                                        round(r_value(da_area_est, expected), 2),\n",
    "                                        round(r_value(ct_dasy_est, expected),2 ),\n",
    "                                        round(r_value(da_dasy_est, expected), 2)],\n",
    "                                'r2': [round(r_value(ct_area_est, expected)**2, 2),\n",
    "                                        round(r_value(da_area_est, expected)**2, 2),\n",
    "                                        round(r_value(ct_dasy_est, expected)**2, 2),\n",
    "                                        round(r_value(da_dasy_est, expected)**2, 2)]})\n",
    "\n",
    "interp_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually Assess Percent Error of the Area Weighted Interpolation\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "interp_results_gdf.explore(column='area_%_error',\n",
    "    cmap='YlOrRd',\n",
    "    scheme='JenksCaspall',\n",
    "    legend_kwds={'colorbar':False},\n",
    "    style_kwds={'weight':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually Assess Percent Error of the Dasymetric Interpolation\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "interp_results_gdf.explore(column='dasy_%_error',\n",
    "    cmap='YlOrRd',\n",
    "    scheme='JenksCaspall',\n",
    "    legend_kwds={'colorbar':False},\n",
    "    style_kwds={'weight':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Percent Error of Both Methods using a Plotly Facet Map\n",
    "# https://plotly.com/python/choropleth-maps/\n",
    "# https://plotly.github.io/plotly.py-docs/generated/plotly.express.choropleth.html\n",
    "# https://plotly.com/python/facet-plots/\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Convert interp_results_gdf from GeoDataFrame to GeoJson\n",
    "geojson = interp_results_gdf.to_crs(epsg='4326').to_json()\n",
    "geojson = json.loads(geojson)\n",
    "\n",
    "# Reformat the interp_results_gdf for the plot\n",
    "df = pd.DataFrame(interp_results_gdf.drop(columns='geometry'))\n",
    "\n",
    "df = df.rename({'ct_area_%_error':'Source: Census Tracts <br> Method: Area Weighted',\n",
    "                'ct_dasy_%_error':'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                'da_area_%_error':'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                'da_dasy_%_error':'Source: Dissemination Areas <br> Method: Dasymetric',\n",
    "                }, axis=1)\n",
    "\n",
    "df = df.melt(id_vars='nbhd_name',\n",
    "            value_vars=['Source: Census Tracts <br> Method: Area Weighted',\n",
    "                        'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                        'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                        'Source: Dissemination Areas <br> Method: Dasymetric'],\n",
    "            var_name='method', \n",
    "            value_name='Error (%)')\n",
    "\n",
    "# Create the Plotly Express choropleth figure\n",
    "fig = px.choropleth(data_frame=df,\n",
    "                    title=\"Areal Interpolation of 2016 Census Population Data to Ottawa, ON Neighborhoods\",\n",
    "                    locations='nbhd_name',\n",
    "                    geojson=geojson,\n",
    "                    featureidkey='properties.nbhd_name',\n",
    "                    color='Error (%)',\n",
    "                    facet_col='method',\n",
    "                    facet_col_wrap=2,\n",
    "                    range_color=[0,100],\n",
    "                    color_continuous_scale='Inferno',\n",
    "                    projection='mercator',\n",
    "                    fitbounds=\"locations\",\n",
    "                    height=800, width=800)\n",
    "         \n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68824b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1:1 Facet Plots using Plotly\n",
    "# -------------------------------------\n",
    "# https://plotly.com/python/line-and-scatter/\n",
    "# https://plotly.github.io/plotly.py-docs/generated/plotly.express.scatter.html\n",
    "# https://plotly.com/python/facet-plots/\n",
    "\n",
    "# Reformat the interp_results_gdf for the plot\n",
    "# --------------------------------------------\n",
    "\n",
    "# Convert the interpolation results to a DataFrame\n",
    "df = pd.DataFrame(interp_results_gdf.drop(columns='geometry'))\n",
    "\n",
    "# Rename the results columns as they will become the facet plot labels\n",
    "df = df.rename({'ct_area_interp_est':'Source: Census Tracts <br> Method: Area Weighted',\n",
    "                'ct_dasy_interp_est':'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                'da_area_interp_est':'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                'da_dasy_interp_est':'Source: Dissemination Areas <br> Method: Dasymetric'},\n",
    "                axis=1)\n",
    "\n",
    "# Combine all the results columns into one column\n",
    "df = df.melt(id_vars=['nbhd_name', 'nbhd_pop_est'],\n",
    "            value_vars=['Source: Census Tracts <br> Method: Area Weighted',\n",
    "                        'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                        'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                        'Source: Dissemination Areas <br> Method: Dasymetric'],\n",
    "            var_name='method', \n",
    "            value_name='interp_pop_est')\n",
    "\n",
    "# Add a percent error column\n",
    "estimated = df['interp_pop_est']\n",
    "expected = df['nbhd_pop_est']\n",
    "df['%_error'] = round(percent_error(estimated, expected), 1)\n",
    "\n",
    "# Create the Plotly Express Scatter figure\n",
    "fig = px.scatter(data_frame=df,\n",
    "                title=\"Areal Interpolation of 2016 Census Population Data to Ottawa, ON Neighborhoods\",\n",
    "                x='nbhd_pop_est',\n",
    "                y='interp_pop_est',\n",
    "                height=800, width=800,\n",
    "                color='%_error',\n",
    "                facet_col='method',\n",
    "                facet_col_wrap=2,\n",
    "                hover_name='nbhd_name',\n",
    "                labels={'interp_pop_est': 'Interpolated Population',\n",
    "                        'nbhd_pop_est': ' Estimated Population'},\n",
    "                color_continuous_scale='Inferno',\n",
    "                range_color=[0,100])\n",
    "\n",
    "# Create the 1:1 line\n",
    "line_max = max([max(df['interp_pop_est']), max(df['nbhd_pop_est'])])\n",
    "line_min = min([min(df['interp_pop_est']), min(df['nbhd_pop_est'])])\n",
    "\n",
    "fig.update_layout(shapes=[\n",
    "        dict(type='line', xref='x', yref='y',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x2', yref='y2',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x3', yref='y3',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x4', yref='y4',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1)])\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf921f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 - Areal Interpolation of Synthetic Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ccf52",
   "metadata": {},
   "source": [
    "### Generate Synthetic Population Data\n",
    "\n",
    "- Falls within:\n",
    "  - Zones that allow residents\n",
    "  - Urban land cover types\n",
    "- Population counts based on 2016 census dissemination areas (finer scale than census tracts data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ee156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clipped dissemination areas\n",
    "# ----------------------------------\n",
    "\n",
    "# Read the dissemination areas\n",
    "da_gdf = gpd.read_file('data/ottawa_da_pop_2016.gpkg')\n",
    "\n",
    "# Extract the urban landcover (pixel value of 17) from the landcover raster\n",
    "raster_path = 'data/ottawa_landcover.tif'\n",
    "urban_landcover_gdf = tobler.dasymetric.extract_raster_features(gdf=nbhd_gdf,\n",
    "                                                                raster_path=raster_path,\n",
    "                                                                pixel_values=17)\n",
    "urban_landcover_gdf = urban_landcover_gdf.to_crs(epsg=32618)\n",
    "\n",
    "# Read the Ottawa zoning\n",
    "zoning_gdf = gpd.read_file('data/ottawa_zoning.gpkg')\n",
    "\n",
    "# Only keep the zones that residents can live in\n",
    "people_zones = ['R1', 'R2', 'R3', 'R4', 'R5', 'RM', 'LC', 'GM', 'TM',\n",
    "                'AM','MC','MD', 'AG', 'RR','RU','VM', 'V1','V2','V3']\n",
    "\n",
    "zoning_gdf = zoning_gdf[zoning_gdf['zone_main'].isin(people_zones)]\n",
    "\n",
    "# Clip the dissemination areas to the urban landcover and the zoning\n",
    "da_clip_gdf = gpd.clip(gdf=da_gdf, mask=zoning_gdf)\n",
    "da_clip_gdf = gpd.clip(gdf=da_clip_gdf, mask=urban_landcover_gdf)\n",
    "\n",
    "# ~2 mins ; ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points in the clipped dissemination areas\n",
    "# ------------------------------------------------\n",
    "\n",
    "def random_points(row, n_column, geom_column, divisor=1, min_n=1):\n",
    "    ''' Returns n number of random points within GeoDataFrame polygons.\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    row : Pandas Series\n",
    "        Must contain:\n",
    "        - A column containing the desired number of points in each polygons\n",
    "        - A column containing polygon geometry\n",
    "\n",
    "    n_column : string\n",
    "        - The name of the column that contains the desired number of points\n",
    "\n",
    "    geom_column : string\n",
    "        - The name of the column that contains the GeoDataBase geometry\n",
    "\n",
    "    divisor : int (default = 1)\n",
    "        - A value to reduce the number of points by that amount\n",
    "        - Good for reducing computation time\n",
    "\n",
    "    min_n : int (default = 1)\n",
    "        - The minimum number of points in polygon\n",
    "        - Good for forcing all polygons to have at least 1 point\n",
    "    '''\n",
    "    \n",
    "    number = round((row[n_column] / divisor), 0) #/100 == 1.5min; /50=2.5mins; /10=16mins\n",
    "    if number < min_n:\n",
    "        number = min_n\n",
    "    polygon = row[geom_column]\n",
    "    points = []\n",
    "    min_x, min_y, max_x, max_y = polygon.bounds\n",
    "    while len(points) < number:\n",
    "        point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n",
    "        #if polygon.contains(point):\n",
    "        if point.intersects(polygon):\n",
    "            points.append(point)\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78988b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random points\n",
    "synth_points_srs = da_clip_gdf.apply(func=random_points, \n",
    "                            args=('da_pop_2016', 'geometry', 10, 1), axis=1)\n",
    "\n",
    "# The output is a Series so convert it to a list\n",
    "synth_points_list = list(synth_points_srs)\n",
    "\n",
    "# Flatten the list of lists so each item in the list is a point\n",
    "synth_points_flat_list = []\n",
    "for i in synth_points_list:\n",
    "    for j in i:\n",
    "        synth_points_flat_list.append(j)\n",
    "\n",
    "# Create GeoDataFrame of the synthetic points using the flat list as the geometry column\n",
    "synth_points_gdf = gpd.GeoDataFrame(geometry=synth_points_flat_list, crs=\"EPSG:32618\")\n",
    "\n",
    "# ~15-20 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#synth_points_gdf.to_file('data/synth_points_gdf.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_points_gdf = gpd.read_file(\"data/synth_points_gdf.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the census tracts' synthetic populations\n",
    "\n",
    "# Spatial join: synth_people_gdf ~ census_tracts\n",
    "ct_points_gdf = gpd.sjoin(synth_points_gdf, ct_gdf, how='inner', predicate='intersects')\n",
    "ct_points_gdf['ct_synth_pop'] = 1\n",
    "\n",
    "# Sum the points that fall in each census tract - this is the population of the census tract\n",
    "ct_points_sums_gdf = ct_points_gdf.groupby(['ctuid']).sum()\n",
    "\n",
    "# Merge the counts with the census tracts\n",
    "ct_synth_gdf = ct_gdf.merge(ct_points_sums_gdf[['ct_synth_pop']], on='ctuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c40494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the dissemination areas' synthetic populations\n",
    "\n",
    "# Spatial join: synth_people_gdf ~ da_gdf\n",
    "da_points_gdf = gpd.sjoin(synth_points_gdf, da_gdf, how='inner', predicate='intersects')\n",
    "da_points_gdf['da_synth_pop'] = 1\n",
    "\n",
    "# Sum the points that fall in each dissemination areas - this is the population of the dissemination area\n",
    "da_points_sums_gdf = da_points_gdf.groupby(['dauid']).sum()\n",
    "\n",
    "# Merge the counts with the census tracts\n",
    "da_synth_gdf = da_gdf.merge(da_points_sums_gdf[['da_synth_pop']], on='dauid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the neighborhoods' synthetic populations\n",
    "\n",
    "# Spatial join: synthetic points to neighborhoods\n",
    "nbhd_points_gdf = gpd.sjoin(synth_points_gdf, nbhd_gdf, how='inner', predicate='intersects')\n",
    "nbhd_points_gdf['nbhd_synth_pop'] = 1\n",
    "\n",
    "# Sum the points that fall in each neighborhood - this is the population of the neighborhood\n",
    "nbhd_points_sums_gdf = nbhd_points_gdf.groupby(['nbhd_name']).sum()\n",
    "\n",
    "# Merge the counts with the neighborhoods\n",
    "nbhd_synth_gdf = nbhd_gdf.merge(nbhd_points_sums_gdf[['nbhd_synth_pop']], on='nbhd_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total points in the census tracts, dissemination areas, and neighborhoods\n",
    "\n",
    "print(ct_synth_gdf['ct_synth_pop'].sum())\n",
    "print(da_synth_gdf['da_synth_pop'].sum())\n",
    "print(nbhd_synth_gdf['nbhd_synth_pop'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area weighted interpolation: synthetic census tracts to neighborhoods\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "ct_area_interp_gdf = tobler.area_weighted.area_interpolate(source_df=ct_synth_gdf, \n",
    "                                                    target_df=nbhd_synth_gdf,\n",
    "                                                    extensive_variables=['ct_synth_pop'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "ct_area_interp_gdf['ct_synth_pop'] = ct_area_interp_gdf['ct_synth_pop'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "ct_area_interp_gdf = ct_area_interp_gdf.rename({'ct_synth_pop':'ct_area_interp_est'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68009c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area weighted interpolation: synthetic dissemination areas to neighborhoods\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "da_area_interp_gdf = tobler.area_weighted.area_interpolate(source_df=da_synth_gdf, \n",
    "                                                    target_df=nbhd_synth_gdf,\n",
    "                                                    extensive_variables=['da_synth_pop'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "da_area_interp_gdf['da_synth_pop'] = da_area_interp_gdf['da_synth_pop'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "da_area_interp_gdf = da_area_interp_gdf.rename({'da_synth_pop':'da_area_interp_est'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasymetric interpolation: synthetic census tracts + urban landover to neighborhoods\n",
    "#------------------------------------------------------------------------------------\n",
    "\n",
    "# Perform dasymetric interpolation\n",
    "ct_dasy_interp_gdf = tobler.dasymetric.masked_area_interpolate(source_df=ct_synth_gdf, \n",
    "                                                        target_df=nbhd_synth_gdf,\n",
    "                                                        raster='data/ottawa_landcover.tif',\n",
    "                                                        codes=[17],\n",
    "                                                        extensive_variables=['ct_synth_pop'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "ct_dasy_interp_gdf['ct_synth_pop'] = ct_dasy_interp_gdf['ct_synth_pop'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "ct_dasy_interp_gdf = ct_dasy_interp_gdf.rename({'ct_synth_pop':'ct_dasy_interp_est'}, axis=1)\n",
    "\n",
    "# ~30 s ; ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasymetric interpolation: synthetic dissemination areas + urban landover to neighborhoods\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "# Perform dasymetric interpolation\n",
    "da_dasy_interp_gdf = tobler.dasymetric.masked_area_interpolate(source_df=da_synth_gdf, \n",
    "                                                        target_df=nbhd_synth_gdf,\n",
    "                                                        raster='data/ottawa_landcover.tif',\n",
    "                                                        codes=[17],\n",
    "                                                        extensive_variables=['da_synth_pop'])\n",
    "\n",
    "# Round the interpolation results to the nearest integer and change the type to integer\n",
    "# (Population counts must be integers)\n",
    "da_dasy_interp_gdf['da_synth_pop'] = da_dasy_interp_gdf['da_synth_pop'].round(decimals=0).astype(int)\n",
    "\n",
    "# Rename the results column for clarity later\n",
    "da_dasy_interp_gdf = da_dasy_interp_gdf.rename({'da_synth_pop':'da_dasy_interp_est'}, axis=1)\n",
    "\n",
    "# ~1.5 mins ; ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the results for comparison\n",
    "#---------------------------------\n",
    "\n",
    "# Create a list of the GeoDataFrames (drop the redundant geometry)\n",
    "dfs = [nbhd_synth_gdf,\n",
    "        ct_area_interp_gdf.drop(columns='geometry'),\n",
    "        ct_dasy_interp_gdf.drop(columns='geometry'),\n",
    "        da_area_interp_gdf.drop(columns='geometry'),\n",
    "        da_dasy_interp_gdf.drop(columns='geometry'),]\n",
    "\n",
    "# Concatenate the GeoDataFrames\n",
    "interp_results_gdf = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Get into on the new interpolation results GeoDataFrame\n",
    "interp_results_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89657d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Results\n",
    "# ----------------\n",
    "\n",
    "ct_area_est = interp_results_gdf['ct_area_interp_est']\n",
    "ct_dasy_est = interp_results_gdf['ct_dasy_interp_est']\n",
    "da_area_est = interp_results_gdf['da_area_interp_est']\n",
    "da_dasy_est = interp_results_gdf['da_dasy_interp_est']\n",
    "expected = interp_results_gdf['nbhd_synth_pop']\n",
    "\n",
    "# Percent Error - create new columns in interp_results_gdf\n",
    "interp_results_gdf['ct_area_%_error'] = round(percent_error(ct_area_est, expected), 1)\n",
    "interp_results_gdf['ct_dasy_%_error'] = round(percent_error(ct_dasy_est, expected), 1)\n",
    "interp_results_gdf['da_area_%_error'] = round(percent_error(da_area_est, expected), 1)\n",
    "interp_results_gdf['da_dasy_%_error'] = round(percent_error(da_dasy_est, expected), 1)\n",
    "\n",
    "# Other statistics - create DataFrame of statistics\n",
    "interp_stats_df = pd.DataFrame({'Interpolation Method': ['Area Weighted','Area Weighted',\n",
    "                                                        'Dasymetric', 'Dasymetric'],\n",
    "                                'Source Geographies': ['Census Tracts', 'Dissemination Areas',\n",
    "                                                       'Census Tracts', 'Dissemination Areas'],\n",
    "                                'RMSE': [round(rmse(ct_area_est, expected), 2),\n",
    "                                        round(rmse(da_area_est, expected), 2),\n",
    "                                        round(rmse(ct_dasy_est, expected), 2),\n",
    "                                        round(rmse(da_dasy_est, expected), 2)],\n",
    "                                'NRMSE': [round(nrmse(ct_area_est, expected), 2),\n",
    "                                        round(nrmse(da_area_est, expected), 2),\n",
    "                                        round(nrmse(ct_dasy_est, expected), 2),\n",
    "                                        round(nrmse(da_dasy_est, expected), 2)],            \n",
    "                                'MBE': [round(mbe(ct_area_est, expected), 2),\n",
    "                                        round(mbe(da_area_est, expected), 2),\n",
    "                                        round(mbe(ct_dasy_est, expected), 2),\n",
    "                                        round(mbe(da_dasy_est, expected), 2)],\n",
    "                                'MAE': [round(mae(ct_area_est, expected), 2),\n",
    "                                        round(mae(da_area_est, expected), 2),\n",
    "                                        round(mae(ct_dasy_est, expected), 2),\n",
    "                                        round(mae(da_dasy_est, expected), 2)],\n",
    "                                'r': [round(r_value(ct_area_est, expected),2 ),\n",
    "                                        round(r_value(da_area_est, expected), 2),\n",
    "                                        round(r_value(ct_dasy_est, expected),2 ),\n",
    "                                        round(r_value(da_dasy_est, expected), 2)],\n",
    "                                'r2': [round(r_value(ct_area_est, expected)**2, 2),\n",
    "                                        round(r_value(da_area_est, expected)**2, 2),\n",
    "                                        round(r_value(ct_dasy_est, expected)**2, 2),\n",
    "                                        round(r_value(da_dasy_est, expected)**2, 2)]})\n",
    "\n",
    "interp_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca075c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Percent Error of Both Methods using a Plotly Facet Map\n",
    "# https://plotly.com/python/choropleth-maps/\n",
    "# https://plotly.github.io/plotly.py-docs/generated/plotly.express.choropleth.html\n",
    "# https://plotly.com/python/facet-plots/\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Convert interp_results_gdf from GeoDataFrame to GeoJson\n",
    "geojson = interp_results_gdf.to_crs(epsg='4326').to_json()\n",
    "geojson = json.loads(geojson)\n",
    "\n",
    "# Reformat the interp_results_gdf for the plot\n",
    "df = pd.DataFrame(interp_results_gdf.drop(columns='geometry'))\n",
    "\n",
    "df = df.rename({'ct_area_%_error':'Source: Census Tracts <br> Method: Area Weighted',\n",
    "                'ct_dasy_%_error':'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                'da_area_%_error':'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                'da_dasy_%_error':'Source: Dissemination Areas <br> Method: Dasymetric',\n",
    "                }, axis=1)\n",
    "\n",
    "df = df.melt(id_vars='nbhd_name',\n",
    "            value_vars=['Source: Census Tracts <br> Method: Area Weighted',\n",
    "                        'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                        'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                        'Source: Dissemination Areas <br> Method: Dasymetric'],\n",
    "            var_name='method', \n",
    "            value_name='Error (%)')\n",
    "\n",
    "# Create the Plotly Express choropleth figure\n",
    "fig = px.choropleth(data_frame=df,\n",
    "                    title=\"Areal Interpolation of Synthetic Population Data to Ottawa, ON Neighborhoods\",\n",
    "                    locations='nbhd_name',\n",
    "                    geojson=geojson,\n",
    "                    featureidkey='properties.nbhd_name',\n",
    "                    color='Error (%)',\n",
    "                    facet_col='method',\n",
    "                    facet_col_wrap=2,\n",
    "                    range_color=[0,100],\n",
    "                    color_continuous_scale='Inferno',\n",
    "                    projection='mercator',\n",
    "                    fitbounds=\"locations\",\n",
    "                    height=800, width=800)\n",
    "         \n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f1e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1:1 Facet Plots using Plotly\n",
    "# -------------------------------------\n",
    "# https://plotly.com/python/line-and-scatter/\n",
    "# https://plotly.github.io/plotly.py-docs/generated/plotly.express.scatter.html\n",
    "# https://plotly.com/python/facet-plots/\n",
    "\n",
    "# Reformat the interp_results_gdf for the plot\n",
    "# --------------------------------------------\n",
    "\n",
    "# Convert the interpolation results to a DataFrame\n",
    "df = pd.DataFrame(interp_results_gdf.drop(columns='geometry'))\n",
    "\n",
    "# Rename the results columns as they will become the facet plot labels\n",
    "df = df.rename({'ct_area_interp_est':'Source: Census Tracts <br> Method: Area Weighted',\n",
    "                'ct_dasy_interp_est':'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                'da_area_interp_est':'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                'da_dasy_interp_est':'Source: Dissemination Areas <br> Method: Dasymetric'},\n",
    "                axis=1)\n",
    "\n",
    "# Combine all the results columns into one column\n",
    "df = df.melt(id_vars=['nbhd_name', 'nbhd_synth_pop'],\n",
    "            value_vars=['Source: Census Tracts <br> Method: Area Weighted',\n",
    "                        'Source: Census Tracts <br> Method: Dasymetric',\n",
    "                        'Source: Dissemination Areas <br> Method: Area Weighted',\n",
    "                        'Source: Dissemination Areas <br> Method: Dasymetric'],\n",
    "            var_name='method', \n",
    "            value_name='interp_pop_est')\n",
    "\n",
    "# Add a percent error column\n",
    "estimated = df['interp_pop_est']\n",
    "expected = df['nbhd_synth_pop']\n",
    "df['%_error'] = round(percent_error(estimated, expected), 1)\n",
    "\n",
    "# Create the Plotly Express Scatter figure\n",
    "fig = px.scatter(data_frame=df,\n",
    "                title=\"Areal Interpolation of Synthetic Population Data to Ottawa, ON Neighborhoods\",\n",
    "                x='nbhd_synth_pop',\n",
    "                y='interp_pop_est',\n",
    "                height=800, width=800,\n",
    "                color='%_error',\n",
    "                facet_col='method',\n",
    "                facet_col_wrap=2,\n",
    "                hover_name='nbhd_name',\n",
    "                labels={'interp_pop_est': 'Interpolated Population',\n",
    "                        'nbhd_synth_pop': ' Estimated Population'},\n",
    "                color_continuous_scale='Inferno',\n",
    "                range_color=[0,100])\n",
    "\n",
    "# Create the 1:1 line\n",
    "line_max = max([max(df['interp_pop_est']), max(df['nbhd_synth_pop'])])\n",
    "line_min = min([min(df['interp_pop_est']), min(df['nbhd_synth_pop'])])\n",
    "\n",
    "fig.update_layout(shapes=[\n",
    "        dict(type='line', xref='x', yref='y',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x2', yref='y2',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x3', yref='y3',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1),\n",
    "        dict(type='line', xref='x4', yref='y4',\n",
    "            x0=line_min, y0=line_min, x1=line_max, y1=line_max, line_width=1)])\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
